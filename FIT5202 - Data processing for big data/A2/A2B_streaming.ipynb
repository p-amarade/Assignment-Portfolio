{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "#import libraries\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.0.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0 pyspark-shell'\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import countDistinct\n",
    "#Two local core\n",
    "master = \"local[2]\"\n",
    "app_name = \"Assignment2B\"\n",
    "# Setup configuration parameters for Spark\n",
    "spark_conf = SparkConf().setMaster(master).setAppName(app_name)\n",
    "spark_conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "sc = SparkContext.getOrCreate(spark_conf)\n",
    "spark = SparkSession(sc)\n",
    "sc.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "#Using same topic from Task 1\n",
    "topic = \"bureau\"\n",
    "df_bureau = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"127.0.0.1:9092\") \\\n",
    "    .option(\"subscribe\", topic) \\\n",
    "    .load()\n",
    "\n",
    "topic = \"customer\"\n",
    "df_customer = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"127.0.0.1:9092\") \\\n",
    "    .option(\"subscribe\", topic) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the key/value from the kafka data stream to string\n",
    "df_bureau = df_bureau.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "df_customer = df_customer.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "#Define a schema according to our data\n",
    "schema_bureau = ArrayType(StructType([    \n",
    "    StructField('ID', StringType(), True), \n",
    "    StructField('SELF-INDICATOR', StringType(), True),    \n",
    "    StructField('MATCH-TYPE', StringType(), True),\n",
    "    StructField('ACCT-TYPE', StringType(), True),    \n",
    "    StructField('CONTRIBUTOR-TYPE', StringType(), True),\n",
    "    StructField('DATE-REPORTED', StringType(), True), \n",
    "    StructField('OWNERSHIP-IND', StringType(), True),    \n",
    "    StructField('ACCOUNT-STATUS', StringType(), True),\n",
    "    StructField('DISBURSED-DT', StringType(), True), \n",
    "    StructField('CLOSE-DT', StringType(), True),    \n",
    "    StructField('LAST-PAYMENT-DATE', StringType(), True),\n",
    "    StructField('CREDIT-LIMIT/SANC AMT', StringType(), True), \n",
    "    StructField('DISBURSED-AMT/HIGH CREDIT', StringType(), True),    \n",
    "    StructField('INSTALLMENT-AMT', StringType(), True),\n",
    "    StructField('CURRENT-BAL', StringType(), True), \n",
    "    StructField('INSTALLMENT-FREQUENCY', StringType(), True),    \n",
    "    StructField('OVERDUE-AMT', StringType(), True),\n",
    "    StructField('WRITE-OFF-AMT', StringType(), True),\n",
    "    StructField('ASSET_CLASS', StringType(), True),    \n",
    "    StructField('REPORTED DATE - HIST', StringType(), True),\n",
    "    StructField('DPD - HIST', StringType(), True),    \n",
    "    StructField('CUR BAL - HIST', StringType(), True),\n",
    "    StructField('AMT OVERDUE - HIST', StringType(), True), \n",
    "    StructField('AMT PAID - HIST', StringType(), True),    \n",
    "    StructField('TENURE', StringType(), True), \n",
    "    StructField('ts', TimestampType(), True) \n",
    "    \n",
    "]))\n",
    "\n",
    "schema_customer = ArrayType(StructType([    \n",
    "    StructField('ID', StringType(), True), \n",
    "    StructField('InstlmentMode', StringType(), True),    \n",
    "    StructField('LoanStatus', StringType(), True),\n",
    "    StructField('PaymentMode', StringType(), True),    \n",
    "    StructField('BranchID', StringType(), True),\n",
    "    StructField('Area', StringType(), True), \n",
    "    StructField('Tenure', StringType(), True),    \n",
    "    StructField('AssetCost', StringType(), True),\n",
    "    StructField('AmountFinance', StringType(), True), \n",
    "    StructField('DisbursalAmount', StringType(), True),    \n",
    "    StructField('EMI', StringType(), True),\n",
    "    StructField('DisbursalDate', StringType(), True), \n",
    "    StructField('MaturityDAte', StringType(), True),    \n",
    "    StructField('AuthDate', StringType(), True),\n",
    "    StructField('AssetID', StringType(), True), \n",
    "    StructField('ManufacturerID', StringType(), True),    \n",
    "    StructField('SupplierID', StringType(), True),\n",
    "    StructField('LTV', StringType(), True),\n",
    "    StructField('SEX', StringType(), True),    \n",
    "    StructField('AGE', StringType(), True),\n",
    "    StructField('MonthlyIncome', StringType(), True),    \n",
    "    StructField('City', StringType(), True),\n",
    "    StructField('State', StringType(), True), \n",
    "    StructField('ZiPCODE', StringType(), True),    \n",
    "    StructField('Top-up Month', StringType(), True), \n",
    "    StructField('ts', TimestampType(), True) \n",
    "    \n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsed schema\n",
    "df_bureau=df_bureau.select(F.from_json(F.col(\"value\").cast(\"string\"), schema_bureau).alias('parsed_value'))\n",
    "df_bureau = df_bureau.select(F.explode(F.col(\"parsed_value\")).alias('unnested_value'))  \n",
    "df_customer = df_customer.select(F.from_json(F.col(\"value\").cast(\"string\"), schema_customer).alias('parsed_value'))\n",
    "df_customer = df_customer.select(F.explode(F.col(\"parsed_value\")).alias('unnested_value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unnested the schema\n",
    "df_formatted_bureau = df_bureau.select(\n",
    "                    F.col(\"unnested_value.ID\").alias(\"ID1\"),\n",
    "                    F.col(\"unnested_value.SELF-INDICATOR\").alias(\"SELF-INDICATOR\"),\n",
    "                    F.col(\"unnested_value.MATCH-TYPE\").alias(\"MATCH-TYPE\"),\n",
    "                    F.col(\"unnested_value.ACCT-TYPE\").alias(\"ACCT-TYPE\"),\n",
    "                    F.col(\"unnested_value.CONTRIBUTOR-TYPE\").alias(\"CONTRIBUTOR-TYPE\"),\n",
    "                    F.col(\"unnested_value.DATE-REPORTED\").alias(\"DATE-REPORTED\"),\n",
    "                    F.col(\"unnested_value.OWNERSHIP-IND\").alias(\"OWNERSHIP-IND\"),\n",
    "                    F.col(\"unnested_value.ACCOUNT-STATUS\").alias(\"ACCOUNT-STATUS\"),\n",
    "                    F.col(\"unnested_value.DISBURSED-DT\").alias(\"DISBURSED-DT\"),\n",
    "                    F.col(\"unnested_value.CLOSE-DT\").alias(\"CLOSE-DT\"),\n",
    "                    F.col(\"unnested_value.LAST-PAYMENT-DATE\").alias(\"LAST-PAYMENT-DATE\"),\n",
    "                    F.col(\"unnested_value.CREDIT-LIMIT/SANC AMT\").alias(\"CREDIT-LIMIT/SANC AMT\"),\n",
    "                    F.col(\"unnested_value.DISBURSED-AMT/HIGH CREDIT\").alias(\"DISBURSED-AMT/HIGH CREDIT\"),\n",
    "                    F.col(\"unnested_value.INSTALLMENT-AMT\").alias(\"INSTALLMENT-AMT\"),\n",
    "                    F.col(\"unnested_value.CURRENT-BAL\").alias(\"CURRENT-BAL\"),\n",
    "                    F.col(\"unnested_value.INSTALLMENT-FREQUENCY\").alias(\"INSTALLMENT-FREQUENCY\"),\n",
    "                    F.col(\"unnested_value.OVERDUE-AMT\").alias(\"OVERDUE-AMT\"),\n",
    "                    F.col(\"unnested_value.WRITE-OFF-AMT\").alias(\"WRITE-OFF-AMT\"),\n",
    "                    F.col(\"unnested_value.ASSET_CLASS\").alias(\"ASSET_CLASS\"),\n",
    "                    F.col(\"unnested_value.REPORTED DATE - HIST\").alias(\"REPORTED DATE - HIST\"),\n",
    "                    F.col(\"unnested_value.DPD - HIST\").alias(\"DPD - HIST\"),\n",
    "                    F.col(\"unnested_value.CUR BAL - HIST\").alias(\"CUR BAL - HIST\"),\n",
    "                    F.col(\"unnested_value.AMT OVERDUE - HIST\").alias(\"AMT OVERDUE - HIST\"),\n",
    "                    F.col(\"unnested_value.AMT PAID - HIST\").alias(\"AMT PAID - HIST\"),\n",
    "                    F.col(\"unnested_value.TENURE\").alias(\"TENURE\"),\n",
    "                    F.col(\"unnested_value.ts\").alias(\"ts\")\n",
    "                )\n",
    "\n",
    "df_formatted_customer = df_customer.select(\n",
    "                    F.col(\"unnested_value.ID\").alias(\"ID\"),\n",
    "                    F.col(\"unnested_value.InstlmentMode\").alias(\"InstlmentMode\"),\n",
    "                    F.col(\"unnested_value.LoanStatus\").alias(\"LoanStatus\"),\n",
    "                    F.col(\"unnested_value.PaymentMode\").alias(\"PaymentMode\"),\n",
    "                    F.col(\"unnested_value.BranchID\").alias(\"BranchID\"),\n",
    "                    F.col(\"unnested_value.Area\").alias(\"Area\"),\n",
    "                    F.col(\"unnested_value.Tenure\").alias(\"Tenure\"),\n",
    "                    F.col(\"unnested_value.AssetCost\").alias(\"AssetCost\"),\n",
    "                    F.col(\"unnested_value.AmountFinance\").alias(\"AmountFinance\"),\n",
    "                    F.col(\"unnested_value.DisbursalAmount\").alias(\"DisbursalAmount\"),\n",
    "                    F.col(\"unnested_value.EMI\").alias(\"EMI\"),\n",
    "                    F.col(\"unnested_value.DisbursalDate\").alias(\"DisbursalDate\"),\n",
    "                    F.col(\"unnested_value.MaturityDAte\").alias(\"MaturityDAte\"),\n",
    "                    F.col(\"unnested_value.AuthDate\").alias(\"AuthDate\"),\n",
    "                    F.col(\"unnested_value.AssetID\").alias(\"AssetID\"),\n",
    "                    F.col(\"unnested_value.ManufacturerID\").alias(\"ManufacturerID\"),\n",
    "                    F.col(\"unnested_value.SupplierID\").alias(\"SupplierID\"),\n",
    "                    F.col(\"unnested_value.LTV\").alias(\"LTV\"),\n",
    "                    F.col(\"unnested_value.SEX\").alias(\"SEX\"),\n",
    "                    F.col(\"unnested_value.AGE\").alias(\"AGE\"),\n",
    "                    F.col(\"unnested_value.MonthlyIncome\").alias(\"MonthlyIncome\"),\n",
    "                    F.col(\"unnested_value.City\").alias(\"City\"),\n",
    "                    F.col(\"unnested_value.State\").alias(\"State\"),\n",
    "                    F.col(\"unnested_value.ZiPCODE\").alias(\"ZiPCODE\"),\n",
    "                    F.col(\"unnested_value.Top-up Month\").alias(\"Top-up Month\"),\n",
    "                    F.col(\"unnested_value.ts\").alias(\"time\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign watermark and replace value in column SELF-INDICATOR\n",
    "df_formatted_bureau = df_formatted_bureau.withWatermark(\"ts\", \"5 seconds\")\n",
    "df_formatted_customer= df_formatted_customer.withWatermark(\"time\", \"5 seconds\")\n",
    "df_formatted_bureau = df_formatted_bureau.withColumn('SELF-INDICATOR', regexp_replace('SELF-INDICATOR', 'FALSE', '0'))\\\n",
    "    .withColumn('SELF-INDICATOR', regexp_replace('SELF-INDICATOR', 'TRUE', '1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change selected column datatype to integer\n",
    "df_formatted_bureau = df_formatted_bureau.withColumn(\"CREDIT-LIMIT/SANC AMT\",col(\"CREDIT-LIMIT/SANC AMT\").cast(IntegerType()))\\\n",
    "    .withColumn(\"INSTALLMENT-AMT\",col(\"INSTALLMENT-AMT\").cast(IntegerType()))\\\n",
    "    .withColumn(\"SELF-INDICATOR\",col(\"SELF-INDICATOR\").cast(IntegerType()))\\\n",
    "    .withColumn(\"CURRENT-BAL\",col(\"CURRENT-BAL\").cast(IntegerType()))\\\n",
    "    .withColumn(\"OVERDUE-AMT\",col(\"OVERDUE-AMT\").cast(IntegerType())) \\\n",
    "    .withColumn(\"WRITE-OFF-AMT\",col(\"WRITE-OFF-AMT\").cast(IntegerType()))\\\n",
    "    .withColumn(\"TENURE\",col(\"TENURE\").cast(IntegerType()))\n",
    "\n",
    "df_formatted_customer = df_formatted_customer.withColumn(\"AssetCost\",col(\"AssetCost\").cast(IntegerType()))\\\n",
    "    .withColumn(\"DisbursalAmount\",col(\"DisbursalAmount\").cast(IntegerType()))\\\n",
    "    .withColumn(\"EMI\",col(\"EMI\").cast(IntegerType()))\\\n",
    "    .withColumn(\"MonthlyIncome\",col(\"MonthlyIncome\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Groupby bureau stream\n",
    "#Replace SELF-INDICATOR value False to 0, True to 1\n",
    "df_formatted_bureau = df_formatted_bureau.withColumn('SELF-INDICATOR', regexp_replace('SELF-INDICATOR', 'FALSE', '0'))\\\n",
    "    .withColumn('SELF-INDICATOR', regexp_replace('SELF-INDICATOR', 'TRUE', '1'))\n",
    "\n",
    "#Groupby on ID with window 30 seconds, \n",
    "windowedCounts = df_formatted_bureau.groupBy(window(df_formatted_bureau.ts,\"30 seconds\"),df_formatted_bureau.ID1)\\\n",
    "    .agg(F.sum(\"CREDIT-LIMIT/SANC AMT\").alias(\"CREDIT-LIMIT/SANC AMT_sum\"), \n",
    "     F.sum(\"INSTALLMENT-AMT\").alias(\"INSTALLMENT-AMT_sum\"),\n",
    "     F.sum(\"DISBURSED-AMT/HIGH CREDIT\").alias(\"DISBURSED-AMT/HIGH CREDIT_sum\"),\n",
    "     F.sum(\"CURRENT-BAL\").alias(\"CURRENT-BAL_sum\"), \n",
    "     F.sum(\"OVERDUE-AMT\").alias(\"OVERDUE-AMT_sum\"),\n",
    "     F.sum(\"TENURE\").alias(\"TENURE_sum\"),\n",
    "     F.sum('SELF-INDICATOR').alias(\"SELF-INDICATOR_sum\"),\n",
    "     F.count('MATCH-TYPE').alias(\"MATCH-TYPE_dist\"),\n",
    "     F.count('ACCT-TYPE').alias(\"ACCT-TYPE_dist\"),\n",
    "     F.count('CONTRIBUTOR-TYPE').alias(\"CONTRIBUTOR-TYPE_dist\"),\n",
    "     F.count('DATE-REPORTED').alias(\"DATE-REPORTED_dist\"),\n",
    "     F.count('OWNERSHIP-IND').alias(\"OWNERSHIP-IND_dist\"),\n",
    "     F.count('ACCOUNT-STATUS').alias(\"ACCOUNT-STATUS_dist\"),\n",
    "     F.count('DISBURSED-DT').alias(\"DISBURSED-DT_dist\"),\n",
    "     F.count('CLOSE-DT').alias(\"CLOSE-DT_dist\"),\n",
    "     F.count('LAST-PAYMENT-DATE').alias(\"LAST-PAYMENT-DATE_dist\"),\n",
    "     F.count('INSTALLMENT-FREQUENCY').alias(\"INSTALLMENT-FREQUENCY_dist\"),\n",
    "     F.count('ASSET_CLASS').alias(\"ASSET_CLASS_dist\"),\n",
    "     F.count('REPORTED DATE - HIST').alias(\"REPORTED DATE - HIST_dist\"),\n",
    "     F.count('DPD - HIST').alias(\"DPD - HIST_dist\"),\n",
    "     F.count('CUR BAL - HIST').alias(\"CUR BAL - HIST_dist\"),\n",
    "     F.count('AMT OVERDUE - HIST').alias(\"AMT OVERDUE - HIST_dist\"),\n",
    "     F.count('AMT PAID - HIST').alias(\"AMT PAID - HIST_dist\"))\\\n",
    "    .select('window.start','window.end',('*'))\\\n",
    "    .drop('window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Inner join 2 stream on id and if customer ID recived between start and end time of bureau with delay 1 hour\n",
    "joined = df_formatted_customer.join(windowedCounts,\n",
    "  expr(\"\"\"\n",
    "    ID1 = ID AND\n",
    "    time >= start AND\n",
    "    time <= end\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new column named window_start and window_end\n",
    "joined = joined.withColumnRenamed(\"start\",\"window_start\") \\\n",
    "    .withColumnRenamed(\"end\",\"window_end\")\\\n",
    "    .withColumnRenamed(\"time\",\"ts\")\\\n",
    "    .withColumnRenamed(\"Top-up Month\",\"Top-up_Month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select column only 'ID','window_start','window_end','ts','Top-up_Month'\n",
    "joined_s = joined.select('ID','window_start','window_end','ts','Top-up_Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "query = joined_s\\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='20 seconds') \\\n",
    "    .option(\"truncate\",\"false\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 persist the above result in parquet format.\n",
    "query_file_sink = joined_s.writeStream.format(\"parquet\")\\\n",
    "        .outputMode(\"append\")\\\n",
    "        .option(\"path\", \"parquet/joined_df\")\\\n",
    "        .option(\"checkpointLocation\", \"parquet/joined_df/checkpoint\")\\\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Loading the model\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import PipelineModel\n",
    "pipelineModel = PipelineModel.load('topup_pipeline_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill na with 0 to avoid error\n",
    "joined = joined.fillna(0)\n",
    "predDF = pipelineModel.transform(joined)\n",
    "joined_model = predDF.select('ID','window_start','window_end','ts','prediction','Top-up_Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "query1 = joined_model\\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .trigger(processingTime='20 seconds') \\\n",
    "    .option(\"truncate\",\"false\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#persist the above result in parquet format.\n",
    "query_file_sink2 = joined_model.writeStream.format(\"parquet\")\\\n",
    "        .outputMode(\"append\")\\\n",
    "        .option(\"path\", \"parquet/joined_model\")\\\n",
    "        .option(\"checkpointLocation\", \"parquet/joined_model/checkpoint\")\\\n",
    "        .start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
